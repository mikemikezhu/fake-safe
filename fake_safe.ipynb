{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fake_safe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO-UyH73Lnhm",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMBtevytTxyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print('Tensorflow version: {}'.format(tf.__version__))\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, LeakyReLU, BatchNormalization, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from abc import ABC, abstractmethod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMd4KCqjMEn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AbstractModelCreator(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_model(self):\n",
        "        raise NotImplementedError('Abstract class shall not be implemented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss8T7zv7L4NP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorModelCreator(AbstractModelCreator):\n",
        "\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def create_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Flatten(input_shape=self.input_shape))\n",
        "\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(np.prod(self.input_shape), activation='tanh'))\n",
        "        model.add(Reshape(self.input_shape))\n",
        "\n",
        "        print('Generator model:')\n",
        "        model.summary()\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abqj4gKsRsfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorModelCreator(AbstractModelCreator):\n",
        "\n",
        "    def __init__(self, input_shape):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def create_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Flatten(input_shape=self.input_shape))\n",
        "\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(loss='binary_crossentropy', \n",
        "                      optimizer=optimizer, \n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        print('Discriminator model:')\n",
        "        model.summary()\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFBpBZjQSSlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderGanModelCreator(AbstractModelCreator):\n",
        "\n",
        "    def __init__(self, \n",
        "                 encoder_generator, \n",
        "                 encoder_discriminator):\n",
        "        self.encoder_generator = encoder_generator\n",
        "        self.encoder_discriminator = encoder_discriminator\n",
        "\n",
        "    def create_model(self):\n",
        "        # Create logical model to combine encoder generator and encoder discriminator\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(self.encoder_generator)\n",
        "        model.add(self.encoder_discriminator)\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(loss='binary_crossentropy', \n",
        "                      optimizer=optimizer)\n",
        "\n",
        "        print('Encoder GAN model:')\n",
        "        model.summary()\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq9bsPgDYN4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderGanModelCreator(AbstractModelCreator):\n",
        "\n",
        "    def __init__(self, \n",
        "                 encoder_generator, \n",
        "                 decoder_generator):\n",
        "        self.encoder_generator = encoder_generator\n",
        "        self.decoder_generator = decoder_generator\n",
        "\n",
        "    def create_model(self):\n",
        "        # Create logical model to combine encoder generator and decoder generator\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(self.encoder_generator)\n",
        "        model.add(self.decoder_generator)\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(loss='mae', \n",
        "                      optimizer=optimizer)\n",
        "\n",
        "        print('Decoder GAN model:')\n",
        "        model.summary()\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1sk3qKSLqAR",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFdsO30WT0mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import ones\n",
        "from numpy import zeros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H-kCqcvOUTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AbstractModelTrainer(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def train_model(self):\n",
        "        raise NotImplementedError('Abstract class shall not be implemented')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miNCHxmxOi9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderTrainer(AbstractModelTrainer):\n",
        "\n",
        "    def __init__(self, \n",
        "                 encoder_generator,\n",
        "                 encoder_discriminator,\n",
        "                 encoder_gan,\n",
        "                 training_epochs, \n",
        "                 batch_size,\n",
        "                 input_data, # Input data of encoder\n",
        "                 exp_output_data): # Expected output data of encoder\n",
        "        \n",
        "        self.encoder_generator = encoder_generator\n",
        "        self.encoder_discriminator = encoder_discriminator\n",
        "        self.encoder_gan = encoder_gan\n",
        "\n",
        "        self.training_epochs = training_epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.input_data = input_data\n",
        "        self.exp_output_data = exp_output_data\n",
        "\n",
        "        self.y_zeros = zeros((self.batch_size, 1))\n",
        "        self.y_ones = ones((self.batch_size, 1))\n",
        "\n",
        "    def train_model(self):\n",
        "\n",
        "        for current_epoch in range(self.training_epochs):\n",
        "\n",
        "            # Select a random batch of data\n",
        "            input_indexes = np.random.randint(0, self.input_data.shape[0], self.batch_size)\n",
        "            x_input = self.input_data[input_indexes]\n",
        "\n",
        "            output_indexes = np.random.randint(0, self.exp_output_data.shape[0], self.batch_size)\n",
        "            x_exp_output = self.exp_output_data[output_indexes]\n",
        "\n",
        "            # Generate output data via encoder generator\n",
        "            x_gen_output = self.encoder_generator.predict(x_input)\n",
        "            \n",
        "            # ---------------------\n",
        "            #  Train encoder discriminator\n",
        "            # ---------------------\n",
        "            d_loss = self.__train_encoder_discriminator(x_gen_output, x_exp_output)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train encoder generator\n",
        "            # ---------------------\n",
        "            g_loss = self.__train_encoder_generator(x_input)\n",
        "\n",
        "            # Plot the progress\n",
        "            print('[Encoder] - epochs: {}, d_loss: {}, g_loss: {}'.format((current_epoch + 1), d_loss, g_loss))\n",
        "            \n",
        "    def __train_encoder_discriminator(self, x_gen_output, x_exp_output):\n",
        "\n",
        "        # 1) Set discriminator to trainable\n",
        "        self.encoder_discriminator.trainable = True\n",
        "\n",
        "        # 2) Train discriminator\n",
        "        # Generated output is marked as 0\n",
        "        d_loss_fake = self.encoder_discriminator.train_on_batch(x_gen_output, self.y_zeros)\n",
        "\n",
        "        # Expected output is marked as 1\n",
        "        d_loss_real = self.encoder_discriminator.train_on_batch(x_exp_output, self.y_ones)\n",
        "\n",
        "        return 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    def __train_encoder_generator(self, x_input):\n",
        "\n",
        "        # 1) Set discriminator to non-trainable\n",
        "        self.encoder_discriminator.trainable = False\n",
        "\n",
        "        # 2) Set generator to trainable\n",
        "        self.encoder_generator.trainable = True\n",
        "\n",
        "        # 3) Train generator via GAN model\n",
        "        return self.encoder_gan.train_on_batch(x_input, self.y_ones)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "driTXa9jp5Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderTrainer(AbstractModelTrainer):\n",
        "\n",
        "    def __init__(self, \n",
        "                 encoder_generator,\n",
        "                 decoder_generator,\n",
        "                 decoder_gan,\n",
        "                 training_epochs,\n",
        "                 batch_size, \n",
        "                 input_data): # Input data of encoder\n",
        "        \n",
        "        self.encoder_generator = encoder_generator\n",
        "        self.decoder_generator = decoder_generator\n",
        "        self.decoder_gan = decoder_gan\n",
        "\n",
        "        self.training_epochs = training_epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.input_data = input_data\n",
        "\n",
        "    def train_model(self):\n",
        "\n",
        "        for current_epoch in range(self.training_epochs):\n",
        "\n",
        "            # Select a random batch of data\n",
        "            input_indexes = np.random.randint(0, self.input_data.shape[0], self.batch_size)\n",
        "            x_input = self.input_data[input_indexes]\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train decoder generator\n",
        "            # ---------------------\n",
        "            self.__train_decoder_generator(x_input)\n",
        "\n",
        "    def __train_decoder_generator(self, x_input):\n",
        "\n",
        "        # 1) Set encoder generator to non-trainable\n",
        "        self.encoder_generator.trainable = False\n",
        "\n",
        "        # 2) Set decoder generator to trainable\n",
        "        self.decoder_generator.trainable = True\n",
        "\n",
        "        # 3) Train decoder generator via GAN model\n",
        "        self.decoder_generator.train_on_batch(x_input, x_input)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}